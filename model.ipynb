{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and explore it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>AU01</th>\n",
       "      <th>AU02</th>\n",
       "      <th>AU04</th>\n",
       "      <th>AU05</th>\n",
       "      <th>AU06</th>\n",
       "      <th>AU07</th>\n",
       "      <th>AU09</th>\n",
       "      <th>AU10</th>\n",
       "      <th>AU11</th>\n",
       "      <th>...</th>\n",
       "      <th>AU14</th>\n",
       "      <th>AU15</th>\n",
       "      <th>AU17</th>\n",
       "      <th>AU20</th>\n",
       "      <th>AU23</th>\n",
       "      <th>AU24</th>\n",
       "      <th>AU25</th>\n",
       "      <th>AU26</th>\n",
       "      <th>AU28</th>\n",
       "      <th>AU43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.450774</td>\n",
       "      <td>0.289915</td>\n",
       "      <td>0.409713</td>\n",
       "      <td>0.518726</td>\n",
       "      <td>0.086218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187309</td>\n",
       "      <td>0.354838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320690</td>\n",
       "      <td>0.411641</td>\n",
       "      <td>0.431646</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277122</td>\n",
       "      <td>0.335435</td>\n",
       "      <td>0.262999</td>\n",
       "      <td>0.189863</td>\n",
       "      <td>0.051967</td>\n",
       "      <td>0.051370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>0.500450</td>\n",
       "      <td>0.314694</td>\n",
       "      <td>0.625174</td>\n",
       "      <td>0.335747</td>\n",
       "      <td>0.262984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.504238</td>\n",
       "      <td>0.383201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544159</td>\n",
       "      <td>0.440429</td>\n",
       "      <td>0.495913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.514737</td>\n",
       "      <td>0.420401</td>\n",
       "      <td>0.052358</td>\n",
       "      <td>0.143576</td>\n",
       "      <td>0.500994</td>\n",
       "      <td>0.155117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sad</td>\n",
       "      <td>0.273191</td>\n",
       "      <td>0.191327</td>\n",
       "      <td>0.140938</td>\n",
       "      <td>0.358091</td>\n",
       "      <td>0.246593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312881</td>\n",
       "      <td>0.188845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284598</td>\n",
       "      <td>0.761539</td>\n",
       "      <td>0.491468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134049</td>\n",
       "      <td>0.670237</td>\n",
       "      <td>0.024796</td>\n",
       "      <td>0.109462</td>\n",
       "      <td>0.325429</td>\n",
       "      <td>0.191367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion      AU01      AU02      AU04      AU05      AU06  AU07      AU09  \\\n",
       "0  neutral  0.450774  0.289915  0.409713  0.518726  0.086218   0.0  0.187309   \n",
       "1  disgust  0.500450  0.314694  0.625174  0.335747  0.262984   0.0  0.504238   \n",
       "2      sad  0.273191  0.191327  0.140938  0.358091  0.246593   0.0  0.312881   \n",
       "\n",
       "       AU10  AU11  ...      AU14      AU15      AU17  AU20      AU23  \\\n",
       "0  0.354838   0.0  ...  0.320690  0.411641  0.431646   0.0  0.277122   \n",
       "1  0.383201   0.0  ...  0.544159  0.440429  0.495913   0.0  0.514737   \n",
       "2  0.188845   1.0  ...  0.284598  0.761539  0.491468   0.0  0.134049   \n",
       "\n",
       "       AU24      AU25      AU26      AU28      AU43  \n",
       "0  0.335435  0.262999  0.189863  0.051967  0.051370  \n",
       "1  0.420401  0.052358  0.143576  0.500994  0.155117  \n",
       "2  0.670237  0.024796  0.109462  0.325429  0.191367  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/dataset.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['emotion', 'AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09',\n",
       "       'AU10', 'AU11', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU24',\n",
       "       'AU25', 'AU26', 'AU28', 'AU43'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1161, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 313 samples for class neutral\n",
      "Found 80 samples for class disgust\n",
      "Found 73 samples for class sad\n",
      "Found 306 samples for class happy\n",
      "Found 164 samples for class surprise\n",
      "Found 160 samples for class angry\n",
      "Found 65 samples for class fear\n"
     ]
    }
   ],
   "source": [
    "# see class balance\n",
    "for emo in data[\"emotion\"].unique():\n",
    "    print(f\"Found {(data['emotion'] == emo).value_counts().iloc[1]} samples for class {emo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluation model function (from Lab 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model, train_in, train_out, val_in, val_out):\n",
    "    model.fit(train_in, train_out)\n",
    "    predicted_val = model.predict(val_in)\n",
    "\n",
    "    # Evaluate model\n",
    "    accuracy = accuracy_score(val_out, predicted_val)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data and split it so we can train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lenght of each split of the data:  811 233 117 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide labels from inputs/features\n",
    "labels = data[\"emotion\"]\n",
    "inputs = data.drop(\"emotion\", axis=1)\n",
    "\n",
    "# split = Train&Val -> 90 / Test -> 10\n",
    "data_in, test_in, data_out, test_out = train_test_split(inputs, labels, test_size=0.1, random_state=42, stratify=labels)\n",
    "# split = Train -> 70/ Val -> 20\n",
    "train_in, val_in, train_out, val_out = train_test_split(data_in, data_out, test_size=(0.2/0.9), random_state=42, stratify=data_out)\n",
    "print(\"\\nLenght of each split of the data: \", len(train_in), len(val_in), len(test_in), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Random Forest  as the model for the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of classifier in validation set is:  60.94420600858369\n",
      "Accuracy on test set is:  64.95726495726495\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=17)\n",
    "print(\"\\nAccuracy of classifier in validation set is: \", train_and_eval(rf_model, train_in, train_out, val_in, val_out)*100)\n",
    "print(\"Accuracy on test set is: \", accuracy_score(test_out, rf_model.predict(test_in))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what parameters our model is using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'monotonic_cst': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 17,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypertuning parameters for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grid Search\n",
      "\n",
      "Random Forest with best parameters on val set:  59.65665236051502\n",
      "Random Forest with best parameters on test set:  66.66666666666666\n",
      "Best parameters of the model:  {'criterion': 'gini', 'max_depth': 17, 'n_estimators': 130}\n"
     ]
    }
   ],
   "source": [
    "# Defining the parameters to try\n",
    "param_grid = [{\"n_estimators\": [91, 117, 130, 172], \"criterion\": [\"gini\", \"entropy\", \"log_loss\"], \"max_depth\": [3, 7, 17]}]\n",
    "# Hypertuning\n",
    "random_forest_search = GridSearchCV(RandomForestClassifier(random_state=17), param_grid, cv=3)\n",
    "random_forest_search.fit(train_in, train_out)\n",
    "print(\"\\nGrid Search\")\n",
    "print(\"\\nRandom Forest with best parameters on val set: \", accuracy_score(val_out, random_forest_search.best_estimator_.predict(val_in))*100)\n",
    "print(\"Random Forest with best parameters on test set: \", accuracy_score(test_out, random_forest_search.predict(test_in))*100)\n",
    "print(\"Best parameters of the model: \", random_forest_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is not improving much so I'd like to try with a random search instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Randomized Search\n",
      "\n",
      "Random Forest with best parameters on val set:  62.231759656652365\n",
      "Random Forest with best parameters on test set:  69.23076923076923\n",
      "Best parameters of the model:  {'n_estimators': 197, 'max_depth': 33, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "param_dist = [{\"n_estimators\": np.arange(17, 237, 20),\"criterion\": [\"gini\", \"entropy\", \"log_loss\"], \"max_depth\": np.arange(3, 103, 10)}]\n",
    "# Hypertuning\n",
    "random_forest_search_random = RandomizedSearchCV(RandomForestClassifier(random_state=17), param_dist, cv=3)\n",
    "random_forest_search_random.fit(train_in, train_out)\n",
    "print(\"\\n Randomized Search\")\n",
    "print(\"\\nRandom Forest with best parameters on val set: \", accuracy_score(val_out, random_forest_search_random.best_estimator_.predict(val_in))*100)\n",
    "print(\"Random Forest with best parameters on test set: \", accuracy_score(test_out, random_forest_search_random.predict(test_in))*100)\n",
    "print(\"Best parameters of the model: \", random_forest_search_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seem like there is a slight improvement in the accuracy of the validation set, so we keep the resulting model from the Random search.\n",
    "\n",
    "Now to predict labels, let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_to_submit = pd.read_csv(\"data/test_to_submit.csv\")\n",
    "test_to_submit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict and save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predicted_labels = random_forest_search_random.predict(test_to_submit)\n",
    "# Save predictions to 'outputs' file\n",
    "with open(\"outputs\", \"w\") as f:\n",
    "    for label in predicted_labels:\n",
    "        f.write(f\"{label}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
